
=== Object Detection
[.lead]
Java model inference library for the https://github.com/tensorflow/models/blob/master/research/object_detection/README.md[TensorFlow Object Detection API].
Allows real-time localization and identification of multiple objects in a single or batch of images.
Works with all https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md[pre-trained zoo models]
and https://github.com/tensorflow/models/tree/master/research/object_detection/data[object labels].

[cols="1,2", frame=none, grid=none]
|===
| image:object_detection_1.jpg[alt=Object Detection 1, width=100%]
| The file://{docdir}/object-detection/src/main/java/io/mindmodel/services/object/detection/ObjectDetectionService.java[ObjectDetectionService] takes an image or a batch of images and outputs a list of predicted objects bounding boxes
  represented by file://{docdir}/object-detection/src/main/java/io/mindmodel/services/object/detection/domain/ObjectDetection.java[ObjectDetection].
  For the models supporting https://github.com/tensorflow/models/tree/master/research/object_detection#february-9-2018[Instance Segmentation],
  the `ObjectDetectionService` can predict the instance segmentation `masks` in addition to object bounding boxes.

  The file://{docdir}/common/src/main/java/io/mindmodel/services/common/JsonMapperFunction.java[JsonMapperFunction] permits
  converting the `List<ObjectDetection>` into JSON objects and the
  file://{docdir}/object-detection/src/main/java/io/mindmodel/services/object/detection/ObjectDetectionImageAugmenter.java[ObjectDetectionImageAugmenter]
  allow to augment the input image with the detected bounding boxes and segmentation masks.
|===
==== Usage

Add the `object-detection` dependency to the pom (use the latest version available):

[source,xml]
----
<dependency>
    <groupId>io.mindmodel.services</groupId>
    <artifactId>object-detection</artifactId>
    <version>1.0.0-SNAPSHOT</version>
</dependency>
----

===== Example 1: Object Detection

Demonstrate how to use the `ObjectDetectionService` to detect objects in input images, convert the result into JSON or
augment the image with the founded object bounding boxes.

[source,java,linenums]
----
ObjectDetectionService detectionService = new ObjectDetectionService(
 "http://download.tensorflow.org/models/object_detection/faster_rcnn_nas_coco_2018_01_28.tar.gz#frozen_inference_graph.pb", //<1>
 "https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/data/mscoco_label_map.pbtxt", //<2>
 0.4f, //<3>
 false, //<4>
 true); //<5>

byte[] image = GraphicsUtils.loadAsByteArray("classpath:/images/object-detection.jpg"); //<6>

List<ObjectDetection> detectedObjects = detectionService.detect(image); //<7>
----
<1> Downloads and loads a pre-trained `frozen_inference_graph.pb` model directly from the `faster_rcnn_nas_coco.tar.gz` archive in the
Tensorflow model zoo. Mind that on first attempt it will download few hundreds of MBs. The consecutive runs will use the
cached copy (5) instead.
<2> Object category labels (e.g. names) for the model
<3> Confidence threshold - Only object with confidence above the threshold are returned
<4> Indicate that this is not a `mask` (e.g. instance segmentation) model type
<5> Cache the model on the local file system.
<6> Load the input image to evaluate
<7> Detect the objects in the image and represent the result as a list of ObjectDetection instances.

Next you can convert the result in JSON format.

[source,java,linenums]
----
String jsonObjectDetections = new JsonMapperFunction().apply(detectedObjects);
System.out.println(jsonObjectDetections);
----

.Object Detection JSON representation
[source,json]
----
[{"name":"person","confidence":0.9988778,"x1":0.16026746,"y1":0.77476984,"x2":0.20187037,"y2":0.9463669,"cid":1},
  {"name":"kite","confidence":0.9988236,"x1":0.43766645,"y1":0.08992515,"x2":0.49562767,"y2":0.16976416,"cid":38},
  {"name":"person","confidence":0.9973546,"x1":0.08468014,"y1":0.68195003,"x2":0.12139505,"y2":0.84821695,"cid":1},
  {"name":"kite","confidence":0.9886335,"x1":0.2067564,"y1":0.26368475,"x2":0.22546713,"y2":0.31434113,"cid":38}]]
----

Or use the `ObjectDetectionImageAugmenter` to augment the input image with the detected objects.

[source,java,linenums]
----
byte[] annotatedImage = new ObjectDetectionImageAugmenter(false).apply(image, detectedObjects);
IOUtils.write(annotatedImage, new FileOutputStream("./object-detection/target/object-detection-augmented.jpg"));
----

.Augmented Object Detection image
image:{docdir}/object-detection/src/test/resources/doc/object-detection-augmented.jpg[alt=Object Detection, width=60%]

===== Example 2: Instance Segmentation

The file://{docdir}/object-detection/src/test/java/io/mindmodel/services/object/detection/examples/ExampleInstanceSegmentation.java[ExampleInstanceSegmentation.java]
sample shows how to use the `ObjectDetectionService` for `Instance Segmentation`. It requires a
a pre-trained model that supports `MASKS` and setting the instance segmentation (e.g. `useMasks`) flag to true.

[source,java,linenums]
----
ObjectDetectionService detectionService = new ObjectDetectionService(
   "http://download.tensorflow.org/models/object_detection/mask_rcnn_inception_resnet_v2_atrous_coco_2018_01_28.tar.gz#frozen_inference_graph.pb", // <1>
   "https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/data/mscoco_label_map.pbtxt", // <2>
   0.4f, // <3>
   true, // <4>
   true); // <5>

byte[] image = GraphicsUtils.loadAsByteArray("classpath:/images/object-detection.jpg");

List<ObjectDetection> detectedObjects = detectionService.detect(image); // <6>

String jsonObjectDetections = new JsonMapperFunction().apply(detectedObjects); // <7>
System.out.println(jsonObjectDetections);

byte[] annotatedImage = new ObjectDetectionImageAugmenter(true).apply(image, detectedObjects); // <8>
IOUtils.write(annotatedImage, new FileOutputStream("./object-detection/target/object-detection-segmentation-augmented.jpg"));
----
<1> Uses one of the 4 MASK pre-trained models
<2>
<3> Confidence threshold - Only object with confidence above the threshold are returned
<4> Use masks output - For the pre-trained models instruct to use the extended fetch names that include instance segmentation masks as well.
<5> Cache model - Create a local copy of the model to speed up consecutive runs.
<6> Evaluate the model to predict the object in the input image.
<7> Convert the detected object in to JSON array.
<8> Draw the detected object on top of the input image.

.Augmented Object Detection image with the segment masks
image:object-detection-segmentation-augmented.jpg[alt=Object Detection Augmented, width=60%]

==== Models
All pre-trained https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md[detection_model_zoo.md]
models are supported. Following URI notation can be used to download any of the models directly from the zoo.

----
http://<zoo model tar.gz url>#frozen_inference_graph.pb
----

The `frozen_inference_graph.pb` is the frozen model file name within the archive.

NOTE: For some models this name may differ. You have to download and open the archive to find the real name.

TIP: To speedup the bootstrap performance you may consider extracting the `frozen_inference_graph.pb` and caching it
locally. Then you can use the `file://path-to-my-local-copy` URI schema to access it.

Following models can be used for `Instance Segmentation` as well:

[frame=none, grid=none]
|===
| http://download.tensorflow.org/models/object_detection/mask_rcnn_inception_resnet_v2_atrous_coco_2018_01_28.tar.gz[mask_rcnn_inception_resnet_v2_atrous_coco_2018_01_28.tar.gz]
| http://download.tensorflow.org/models/object_detection/mask_rcnn_inception_v2_coco_2018_01_28.tar.gz[mask_rcnn_inception_v2_coco_2018_01_28.tar.gz]
| http://download.tensorflow.org/models/object_detection/mask_rcnn_resnet101_atrous_coco_2018_01_28.tar.gz[mask_rcnn_resnet101_atrous_coco_2018_01_28.tar.gz]
| http://download.tensorflow.org/models/object_detection/mask_rcnn_resnet50_atrous_coco_2018_01_28.tar.gz[mask_rcnn_resnet50_atrous_coco_2018_01_28.tar.gz]
|===

In addition to the model, the `ObjectDetectionService` requires a list of labels that correspond to the categories detectable by the selected model.
All labels files are available in the https://github.com/tensorflow/models/tree/master/research/object_detection/data[object_detection/data] folder.

NOTE: It is important to use the labels that correspond to the model being used! Table below highlights this mapping.

.Relationsip between trained model types and category labels
[%header, cols="1,2", frame=none, grid=none]
|===
| Model
| Labels

| https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md#coco-trained-models[coco]
| https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/data/mscoco_label_map.pbtxt[mscoco_label_map.pbtxt]

| https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md#kitti-trained-models[kitti]
| https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/data/kitti_label_map.pbtxt[kitti_label_map.pbtxt]

| https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md#open-images-trained-models[open-images]
| https://github.com/tensorflow/models/blob/master/research/object_detection/data/oid_bbox_trainable_label_map.pbtxt[oid_bbox_trainable_label_map.pbtxt]

| https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md#inaturalist-species-trained-models[inaturalist-species]
| https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/data/fgvc_2854_classes_label_map.pbtxt[fgvc_2854_classes_label_map.pbtxt]

| https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md#ava-v21-trained-models[ava]
| https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/data/ava_label_map_v2.1.pbtxt[ava_label_map_v2.1.pbtxt]

|===

TIP: For performance reasons you may consider downloading the required label files to the local file system.


==== Build

```
$ ./mvnw clean install
```
